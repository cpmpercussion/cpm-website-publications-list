<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Charles Martin" />
  <title>Publications</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      word-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Publications</h1>
<p class="author">Charles Martin</p>
</header>
<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="doc-bibliography">
<div id="ref-Cormick:2010aa" class="csl-entry" role="doc-biblioentry">
Cormick, H., Forster, B., &amp; Martin, C. (2010). <em><span>THE LAST MAN TO DIE</span></em>. Touring theatrical performance in Canberra, Sydney, and Perth, Australia. <a href="https://charlesmartin.com.au/lmtd/">https://charlesmartin.com.au/lmtd/</a>
</div>
<div id="ref-Cormick:2009aa" class="csl-entry" role="doc-biblioentry">
Cormick, H., Martin, C., &amp; Forster, B. (2009). <em><span class="nocase">Vital LMTD [cross-artform performance by Last Man to Die]</span></em>. <a href="http://www.lastmantodie.net/search/label/vitallmtd">http://www.lastmantodie.net/search/label/vitallmtd</a>
</div>
<div id="ref-Olav-Ellefsen:2019aa" class="csl-entry" role="doc-biblioentry">
Ellefsen, K. O., Martin, C. P., &amp; Torresen, J. (2019). How do mixture density <span>RNNs</span> predict the future? <em>arXiv e-Prints</em>, arXiv:1901.07859. <a href="https://arxiv.org/abs/1901.07859">https://arxiv.org/abs/1901.07859</a>
</div>
<div id="ref-Erdem:2020aa" class="csl-entry" role="doc-biblioentry">
Erdem, C., Lan, Q., Fuhrer, J., Martin, C. P., Torresen, J., &amp; Jensenius, A. R. (2020). Towards playing in the <span>‘air’</span>: Modeling motion-sound energy relationships in electric guitar performance using deep neural networks. In <em>Proceedings of the 17th sound and music computing conference</em> (pp. 177–184). SMC Network. <a href="http://urn.nb.no/URN:NBN:no-82501">http://urn.nb.no/URN:NBN:no-82501</a>
</div>
<div id="ref-Faitas:2019aa" class="csl-entry" role="doc-biblioentry">
Faitas, A., Baumann, S. E., Næss, T. R., Torresen, J., &amp; Martin, C. P. (2019). Generating convincing harmony parts with bidirectional long short-term memory networks. In M. Queiroz &amp; A. X. Sedó (Eds.), <em>Proceedings of the international conference on new interfaces for musical expression</em> (pp. 325–330). UFRGS. <a href="http://www.nime.org/proceedings/2019/nime2019_062.pdf">http://www.nime.org/proceedings/2019/nime2019_062.pdf</a>
</div>
<div id="ref-Finkelmeier:2013aa" class="csl-entry" role="doc-biblioentry">
Finkelmeier, M., Martin, C., &amp; Remington, J. (2013, November). <span>Ensemble Evolution</span>: Showcase concert. <em>Percussive Arts Society International Convention</em>. <a href="https://youtu.be/zqnffMAHbPA">https://youtu.be/zqnffMAHbPA</a>
</div>
<div id="ref-Garcia-Ceja:2018aa" class="csl-entry" role="doc-biblioentry">
Garcia Ceja, E. A., Ellefsen, K. O., Martin, C. P., &amp; Tørresen, J. (2018, July). Tutorial on prediction, interaction, and user behaviour. <em>IEEE World Congress on Computational Intelligence</em>. <a href="https://kaiolae.github.io/wcci2018_prediction_tutorial/">https://kaiolae.github.io/wcci2018_prediction_tutorial/</a>
</div>
<div id="ref-Sanchez:2018aa" class="csl-entry" role="doc-biblioentry">
Gonzalez Sanchez, V. E., Zelechowska, A., Martin, C. P., Johnson, V., Bjerkestrand, K. A. V., &amp; Jensenius, A. R. (2018, June). Bela-based augmented acoustic guitars for inverse sonic microinteraction. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>. <a href="https://doi.org/10.5281/zenodo.1302599">https://doi.org/10.5281/zenodo.1302599</a>
</div>
<div id="ref-Helyard:2014aa" class="csl-entry" role="doc-biblioentry">
Helyard, E., Hunter, A., &amp; Martin, C. (2014). <em><span class="nocase">Helyard, Hunter, Martin: Experimental Music Studio Performance (ANU School of Music and ANU Drill Hall Gallery)</span></em>.
</div>
<div id="ref-Hopgood:2018aa" class="csl-entry" role="doc-biblioentry">
Hopgood, C., Martin, C. P., &amp; Gretarsson, G. J. (2019). Synesthetic: Composing works for marimba and automated lighting. <em>Proceedings of the <span>Australasian</span> Computer Music Conference</em>, 23–27. <a href="https://metatonetransfer.com/preprints/2018-Synesthetic.pdf">https://metatonetransfer.com/preprints/2018-Synesthetic.pdf</a>
</div>
<div id="ref-Jensenius:2017aa" class="csl-entry" role="doc-biblioentry">
Jensenius, A. R., Bjerkestrand, K. A. V., Johnson, V., Gonzalez Sanchez, V. E., Zelechowska, A., &amp; Martin, C. P. (2017, September). Sverm-resonans: Performance installation for acoustically-activated guitars. <em><span class="nocase">Program of the Ultima Contemporary Music Festival, Oslo</span></em>. <a href="http://www.uio.no/english/research/groups/fourms/projects/sverm/events/2017/ultima/index.html">http://www.uio.no/english/research/groups/fourms/projects/sverm/events/2017/ultima/index.html</a>
</div>
<div id="ref-Lai:2010ab" class="csl-entry" role="doc-biblioentry">
Lai, C.-H., &amp; Martin, C. (2010a). <span class="nocase">Strike on Stage</span> 1.2 for percussion and interactive media. In T. Opie (Ed.), <em>Musical program of the <span>Australasian</span> computer music conference</em>. <a href="https://vimeo.com/13543935">https://vimeo.com/13543935</a>
</div>
<div id="ref-Lai:2010aa" class="csl-entry" role="doc-biblioentry">
Lai, C.-H., &amp; Martin, C. (2010b, June). <span class="nocase">Strike on Stage</span> for percussion and interactive media. <em>Musical Program of the International Conference on New Interfaces for Musical Expression</em>. <a href="http://www.nime.org/2010/program.html#Performances">http://www.nime.org/2010/program.html#Performances</a>
</div>
<div id="ref-Li:2020aa" class="csl-entry" role="doc-biblioentry">
Li, S., &amp; Martin, C. P. (2020). Comparing three data representations for music with a sequence-to-sequence model. <em>Australasian Joint Conference on Artificial Intelligence</em>, <em>12576</em>, 16–28. <a href="https://doi.org/10.1007/978-3-030-64984-5_2">https://doi.org/10.1007/978-3-030-64984-5_2</a>
</div>
<div id="ref-Martin:2012fk" class="csl-entry" role="doc-biblioentry">
Martin, C. (2012a). Creating mobile computer music for percussionists: Snow music. In M. Hitchcock &amp; J. Taylor (Eds.), <em>Proceedings of the <span>Australasian</span> computer music conference</em>. Australasian Computer Music Association. <a href="https://doi.org/10.13140/RG.2.1.5150.5687">https://doi.org/10.13140/RG.2.1.5150.5687</a>
</div>
<div id="ref-Martin:2013fk" class="csl-entry" role="doc-biblioentry">
Martin, C. (2013a). Integrating mobile music with percussion performance practice. <em>Proceedings of the International Computer Music Conference</em>, 437–440. <a href="http://hdl.handle.net/2027/spo.bbp2372.2013.073">http://hdl.handle.net/2027/spo.bbp2372.2013.073</a>
</div>
<div id="ref-Martin:2014jk" class="csl-entry" role="doc-biblioentry">
Martin, C. (2014a). Making improvised music for i<span>P</span>ad and percussion with <span>E</span>nsemble <span>M</span>etatone. <em>Proceedings of the <span>Australasian</span> Computer Music Conference</em>, 115–118. <a href="http://hdl.handle.net/1885/95314">http://hdl.handle.net/1885/95314</a>
</div>
<div id="ref-Martin:2013" class="csl-entry" role="doc-biblioentry">
Martin, C. (2013b). Performing with a mobile computer system for vibraphone. In W. Yeo, K. Lee, A. Sigman, J. H., &amp; G. Wakefield (Eds.), <em>Proceedings of the international conference on new interfaces for musical expression</em> (pp. 377–380). Graduate School of Culture Technology, KAIST. <a href="https://doi.org/10.5281/zenodo.1178602">https://doi.org/10.5281/zenodo.1178602</a>
</div>
<div id="ref-Martin:2017aj" class="csl-entry" role="doc-biblioentry">
Martin, C. (2017). Pursuing a sonigraphical ideal at the dawn of the NIME epoch. A commentary on <span>“sonigraphical instruments: From FMOL to the reacTable.”</span> In A. R. Jensenius &amp; M. J. Lyons (Eds.), <em>A <span>NIME</span> reader: Fifteen years of new interfaces for musical expression</em> (pp. 103–105). Springer International Publishing. <a href="https://doi.org/10.1007/978-3-319-47214-0">https://doi.org/10.1007/978-3-319-47214-0</a>
</div>
<div id="ref-Martin:2014db" class="csl-entry" role="doc-biblioentry">
Martin, C. (2014b). <em>Metatone classifier: Ensemble director agent application</em>. Git Repository. <a href="https://doi.org/10.5281/zenodo.51712">https://doi.org/10.5281/zenodo.51712</a>
</div>
<div id="ref-Martin:2009MMus" class="csl-entry" role="doc-biblioentry">
Martin, C. (2009). <em>Percussion and computer in live performance</em> [Master’s thesis, School of Music, The Australian National University]. <a href="http://hdl.handle.net/1885/13813">http://hdl.handle.net/1885/13813</a>
</div>
<div id="ref-Martin:2013mz" class="csl-entry" role="doc-biblioentry">
Martin, C. (2013c). <em><span>M</span>eta<span>T</span>ravels: A prototype touch-screen musical instrument for <span class="nocase">iPad</span></em>. Git Repository. <a href="https://doi.org/10.5281/zenodo.50705">https://doi.org/10.5281/zenodo.50705</a>
</div>
<div id="ref-Martin:2013aa" class="csl-entry" role="doc-biblioentry">
Martin, C. (2013d, May). Nordlig vinter for vibraphone and iOS devices. <em>Musical Program of the International Conference on New Interfaces for Musical Expression</em>.
</div>
<div id="ref-Martin:2013zl" class="csl-entry" role="doc-biblioentry">
Martin, C. (2013e). <em><span>OSC</span> <span>L</span>ogger: A cocoa application for logging <span>OSC</span> messages to a text file</em>. Git Repository. <a href="https://doi.org/10.5281/zenodo.50703">https://doi.org/10.5281/zenodo.50703</a>
</div>
<div id="ref-Martin:2016oq" class="csl-entry" role="doc-biblioentry">
Martin, C. (2016a). <em>BirdsNest app demo</em>. Zenodo. <a href="https://doi.org/10.5281/zenodo.51819">https://doi.org/10.5281/zenodo.51819</a>
</div>
<div id="ref-Martin:2016af" class="csl-entry" role="doc-biblioentry">
Martin, C. (2016b). <em>Birds<span>N</span>est: An iPad-instrument recalling the forest sounds of northern <span>Sweden</span></em>. Git Repository. <a href="https://doi.org/10.5281/zenodo.51604">https://doi.org/10.5281/zenodo.51604</a>
</div>
<div id="ref-Martin:2016dp" class="csl-entry" role="doc-biblioentry">
Martin, C. (2016c). <em>MetaLonsdale app demo</em>. Zenodo. <a href="https://doi.org/10.5281/zenodo.51818">https://doi.org/10.5281/zenodo.51818</a>
</div>
<div id="ref-Martin:2016ag" class="csl-entry" role="doc-biblioentry">
Martin, C. (2016d). <em><span>M</span>eta<span>L</span>onsdale: An <span class="nocase">iPad</span> musical instrument for ensemble improvisation</em>. Git Repository. <a href="https://doi.org/10.5281/zenodo.50716">https://doi.org/10.5281/zenodo.50716</a>
</div>
<div id="ref-Martin:2016fy" class="csl-entry" role="doc-biblioentry">
Martin, C. (2016e). <em>MetaTravels app demo</em>. Zenodo. <a href="https://doi.org/10.5281/zenodo.51814">https://doi.org/10.5281/zenodo.51814</a>
</div>
<div id="ref-Martin:2016gf" class="csl-entry" role="doc-biblioentry">
Martin, C. (2016f). <em>PhaseRings app demo</em>. Zenodo. <a href="https://doi.org/10.5281/zenodo.51822">https://doi.org/10.5281/zenodo.51822</a>
</div>
<div id="ref-Martin:2016ah" class="csl-entry" role="doc-biblioentry">
Martin, C. (2016g). <em><span>P</span>hase<span>R</span>ings: An annular <span class="nocase">iOS</span> instrument for performing expressive music with touch gestures</em>. Git Repository. <a href="https://doi.org/10.5281/zenodo.50860">https://doi.org/10.5281/zenodo.50860</a>
</div>
<div id="ref-Martin:2016lq" class="csl-entry" role="doc-biblioentry">
Martin, C. (2016h). <em>Singing bowls app demo</em>. Zenodo. <a href="https://doi.org/10.5281/zenodo.51821">https://doi.org/10.5281/zenodo.51821</a>
</div>
<div id="ref-Martin:2016ae" class="csl-entry" role="doc-biblioentry">
Martin, C. (2016i). <em>Singing<span>B</span>owls: A minimal prototype touchscreen instrument</em>. Git Repository. <a href="https://doi.org/10.5281/zenodo.51605">https://doi.org/10.5281/zenodo.51605</a>
</div>
<div id="ref-Martin:2016rr" class="csl-entry" role="doc-biblioentry">
Martin, C. (2016j). <em>Snow music app demo</em>. Zenodo. <a href="https://doi.org/10.5281/zenodo.51820">https://doi.org/10.5281/zenodo.51820</a>
</div>
<div id="ref-Martin:2016ad" class="csl-entry" role="doc-biblioentry">
Martin, C. (2016k). <em>Snow<span>M</span>usic: A touchscreen instrument for performing with snow and ice sounds</em>. Git Repository. <a href="https://doi.org/10.5281/zenodo.51630">https://doi.org/10.5281/zenodo.51630</a>
</div>
<div id="ref-Martin:2012yq" class="csl-entry" role="doc-biblioentry">
Martin, C. (2012b). <em>Mobile computer music for percussionists</em> [Master’s thesis, Department of Arts, Communication; Education, Lule<span>å</span> University of Technology]. <a href="https://doi.org/10.13140/RG.2.1.1688.9681">https://doi.org/10.13140/RG.2.1.1688.9681</a>
</div>
<div id="ref-Martin:2013ab" class="csl-entry" role="doc-biblioentry">
Martin, C. (2013f). <em><span>Nordlig Vinter</span> [album]</em>. <a href="https://charlesmartin.bandcamp.com/album/nordlig-vinter">https://charlesmartin.bandcamp.com/album/nordlig-vinter</a>
</div>
<div id="ref-Martin:2015aa" class="csl-entry" role="doc-biblioentry">
Martin, C. (2015, September). Decoding performance with data. <em><span class="nocase">Musicological Society of Australia National Conference</span></em>. <a href="https://metatonetransfer.com/preprints/2015-MSA-DecodingPerformanceWithData.pdf">https://metatonetransfer.com/preprints/2015-MSA-DecodingPerformanceWithData.pdf</a>
</div>
<div id="ref-Martin:2014ad" class="csl-entry" role="doc-biblioentry">
Martin, C. (2014c, November). <span class="nocase">iPads</span> in percussion ensemble. <em><span>Percussive Arts Society International Convention</span></em>. <a href="https://youtu.be/oyW3mFyoz-I">https://youtu.be/oyW3mFyoz-I</a>
</div>
<div id="ref-Martin:2016ac" class="csl-entry" role="doc-biblioentry">
Martin, C. P. (2016a). PhaseRings for iPad ensemble and ensemble director agent [Musical Performance]. <em>Musical Program of the International Conference on Auditory Display</em>, 232–233. <a href="http://www.icad.org/icad2016/proceedings/concert/ICAD2016_paper_99.pdf">http://www.icad.org/icad2016/proceedings/concert/ICAD2016_paper_99.pdf</a>
</div>
<div id="ref-Martin:2018aj" class="csl-entry" role="doc-biblioentry">
Martin, C. P. (2018a). <em>Myo-to-OSC: A pure-python cross-platform solution for simply connecting myo armbands to OSC-connected software.</em> Git Repository. <a href="https://doi.org/10.5281/zenodo.1216169">https://doi.org/10.5281/zenodo.1216169</a>
</div>
<div id="ref-Martin:2016nr" class="csl-entry" role="doc-biblioentry">
Martin, C. P. (2016b). <em>Apps, agents, and improvisation: Ensemble interaction with touch-screen digital musical instruments</em> [PhD thesis, The Australian National University]. <a href="http://hdl.handle.net/1885/101786">http://hdl.handle.net/1885/101786</a>
</div>
<div id="ref-Martin:2017am" class="csl-entry" role="doc-biblioentry">
Martin, C. P. (2017a, June). MicroJam: A social app for making music. <em>Boost - Technology and Equality in Music</em>.
</div>
<div id="ref-Martin:2017ag" class="csl-entry" role="doc-biblioentry">
Martin, C. P. (2017b). <em><span class="nocase">cpmpercussion/gesture-rnn: A deep model of touch-screen ensemble musical performance</span></em>. Git Repository. <a href="https://doi.org/10.5281/zenodo.834268">https://doi.org/10.5281/zenodo.834268</a>
</div>
<div id="ref-Martin:2017ad" class="csl-entry" role="doc-biblioentry">
Martin, C. P. (2017c). <em><span>Neural Touchscreen Ensemble [Performance] 2017-07-03</span></em>. <a href="https://doi.org/10.5281/zenodo.831910">https://doi.org/10.5281/zenodo.831910</a>
</div>
<div id="ref-Martin:2017al" class="csl-entry" role="doc-biblioentry">
Martin, C. P. (2017d, September). Making social music with <span>MicroJam</span>. <em>Cutting Edge Festival: Future Planet, Future Society, Future You</em>.
</div>
<div id="ref-Martin:2017af" class="csl-entry" role="doc-biblioentry">
Martin, C. P. (2017e). Percussionist-centred design for touchscreen digital musical instruments. <em>Contemporary Music Review</em>, <em>36</em>(1–2), 64–85. <a href="https://doi.org/10.1080/07494467.2017.1370794">https://doi.org/10.1080/07494467.2017.1370794</a>
</div>
<div id="ref-Martin:2017aa" class="csl-entry" role="doc-biblioentry">
Martin, C. P. (2018b). <em><span>MicroJam</span>: A mobile app for sharing tiny touch-screen performances</em>. Git Repository. <a href="https://doi.org/10.5281/zenodo.597271">https://doi.org/10.5281/zenodo.597271</a>
</div>
<div id="ref-Martin:2017ak" class="csl-entry" role="doc-biblioentry">
Martin, C. P. (2017f, October). Musical networks: Using recurrent neural networks to model and complement musical creativity. <em>Musikkteknologidagene</em>. <a href="https://doi.org/10.13140/RG.2.2.27125.06887">https://doi.org/10.13140/RG.2.2.27125.06887</a>
</div>
<div id="ref-Martin:2017ah" class="csl-entry" role="doc-biblioentry">
Martin, C. P. (2017g). <em><span class="nocase">cpmpercussion/robojam: A Mixture Density RNN for generating musical touchscreen interactions</span></em>. <a href="https://doi.org/10.5281/zenodo.1064013">https://doi.org/10.5281/zenodo.1064013</a>
</div>
<div id="ref-Martin:2017ao" class="csl-entry" role="doc-biblioentry">
Martin, C. P. (2017h, November). Musical networks and creative <span>AI</span>. <em>Technology and Emotions</em>.
</div>
<div id="ref-Martin:2018ad" class="csl-entry" role="doc-biblioentry">
Martin, C. P. (2018c). <em>Creative-prediction: Tutorials and walkthroughs for predicting creative data with neural networks</em>. Git Repository and Website. <a href="https://doi.org/10.5281/zenodo.1494039">https://doi.org/10.5281/zenodo.1494039</a>
</div>
<div id="ref-Martin:2017ai" class="csl-entry" role="doc-biblioentry">
Martin, C. P., Ellefsen, K. O., &amp; Torresen, J. (2018). <em>Deep predictive models in interactive music</em>. <a href="http://arxiv.org/abs/1801.10492">http://arxiv.org/abs/1801.10492</a>
</div>
<div id="ref-Martin:2017ae" class="csl-entry" role="doc-biblioentry">
Martin, C. P., Ellefsen, K. O., &amp; Torresen, J. (2017, August). Deep models for ensemble touch-screen improvisation. <em>Proceedings of the 12th International Audio Mostly Conference on Augmented and Participatory Sound and Music Experiences</em>. <a href="https://doi.org/10.1145/3123514.3123556">https://doi.org/10.1145/3123514.3123556</a>
</div>
<div id="ref-Martin:2018aa" class="csl-entry" role="doc-biblioentry">
Martin, C. P., &amp; Gardner, H. (2019). Free-improvised rehearsal-as-research for musical <span>HCI</span>. In S. Holland, T. Mudd, K. Wilkie-McKenna, A. McPherson, &amp; M. M. Wanderley (Eds.), <em>New directions in music and human-computer interaction</em> (pp. 269–284). Springer. <a href="https://doi.org/10.1007/978-3-319-92069-6_17">https://doi.org/10.1007/978-3-319-92069-6_17</a>
</div>
<div id="ref-Martin:2020aa" class="csl-entry" role="doc-biblioentry">
Martin, C. P., Glette, K., Nygaard, T. F., &amp; Torresen, J. (2020). Understanding musical predictions with an embodied interface for musical machine learning. <em>Frontiers in Artificial Intelligence</em>, <em>3</em>, 6. <a href="https://doi.org/10.3389/frai.2020.00006">https://doi.org/10.3389/frai.2020.00006</a>
</div>
<div id="ref-Martin:2018af" class="csl-entry" role="doc-biblioentry">
Martin, C. P., Glette, K., Nygaard, T. F., &amp; Torresen, J. (2018, April). Self-awareness in a cyber-physical predictive musical interface. <em>Self-Awareness in Cyber-Physical Systems Workshop</em>. <a href="https://metatonetransfer.com/preprints/2018-self-aware-music-interface-preprint.pdf">https://metatonetransfer.com/preprints/2018-self-aware-music-interface-preprint.pdf</a>
</div>
<div id="ref-Martin:2018ah" class="csl-entry" role="doc-biblioentry">
Martin, C. P., Glette, K., &amp; Tørresen, J. (2018, July). Tutorial on creative prediction with neural networks. <em>The 2018 Conference on Artificial Life</em>. <a href="https://cpmpercussion.github.io/creative-prediction/">https://cpmpercussion.github.io/creative-prediction/</a>
</div>
<div id="ref-Martin:2017an" class="csl-entry" role="doc-biblioentry">
Martin, C. P., Gonzalez Sanchez, V. E., Kelkar, T., Zelechowska, A., Berggren, S. J., Hopgood, C., Wallace, B., Brustad, H., Utne-Reitan, B., Ellefsen, K. O., Nygaard, T. F., Søyseth, V. D., Câmara, G. S., &amp; Diaz, X. A. (2017, September). Ensemble metatone: 3-hour improvised touchscreen performance. <em>Elvelangs i Fakkellys (River Walk by Lantern Light)</em>. <a href="https://youtu.be/NepiJe-TB_Q">https://youtu.be/NepiJe-TB_Q</a>
</div>
<div id="ref-Martin:2015ac" class="csl-entry" role="doc-biblioentry">
Martin, C. P., &amp; Hunter, A. (2015, November). Andromeda is coming. <em>Electrofringe Festival</em>. <a href="https://youtu.be/BhrBdgrBwD0">https://youtu.be/BhrBdgrBwD0</a>
</div>
<div id="ref-Martin:2018ae" class="csl-entry" role="doc-biblioentry">
Martin, C. P., &amp; Jensenius, A. R. (2018, June). Stillness under tension: Performance for <span>Myo</span> armbands and <span>Bela</span> embedded computers. <em>Musical Program of the International Conference on New Interfaces for Musical Expression</em>.
</div>
<div id="ref-Martin:2017zz" class="csl-entry" role="doc-biblioentry">
Martin, C. P., Jensenius, A. R., Bjerkestrand, K. A. V., &amp; Johnson, V. (2017, November). Stillness under tension: Performance for <span>Myo</span> armbands and <span>Bela</span> embedded computers. <em>MusicLab Vol.1: Biophysical Music</em>. <a href="https://doi.org/10.5281/zenodo.1215956">https://doi.org/10.5281/zenodo.1215956</a>
</div>
<div id="ref-Martin:2018ab" class="csl-entry" role="doc-biblioentry">
Martin, C. P., Jensenius, A. R., &amp; Torresen, J. (2018). Composing an ensemble standstill work for myo and bela. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, 196–197. <a href="https://doi.org/10.5281/zenodo.1302543">https://doi.org/10.5281/zenodo.1302543</a>
</div>
<div id="ref-NIME20_8" class="csl-entry" role="doc-biblioentry">
Martin, C. P., Liu, Z., Wang, Y., He, W., &amp; Gardner, H. (2020). Sonic sculpture: Activating engagement with head-mounted augmented reality. In R. Michon &amp; F. Schroeder (Eds.), <em>Proceedings of the international conference on new interfaces for musical expression</em> (pp. 39–42). Birmingham City University. <a href="https://www.nime.org/proceedings/2020/nime2020_paper8.pdf">https://www.nime.org/proceedings/2020/nime2020_paper8.pdf</a>
</div>
<div id="ref-Martin:2019aa" class="csl-entry" role="doc-biblioentry">
Martin, C. P., &amp; Torresen, J. (2019). An interactive musical prediction system with mixture density recurrent neural networks. In M. Queiroz &amp; A. X. Sedó (Eds.), <em>Proceedings of the international conference on new interfaces for musical expression</em> (pp. 260–265). UFRGS. <a href="http://www.nime.org/proceedings/2019/nime2019_050.pdf">http://www.nime.org/proceedings/2019/nime2019_050.pdf</a>
</div>
<div id="ref-Martin:2017ac" class="csl-entry" role="doc-biblioentry">
Martin, C. P., &amp; Torresen, J. (2017a). Exploring social mobile music with tiny touch-screen performances. In T. Lokki, J. Pätynen, &amp; V. Välimäki (Eds.), <em>Proceedings of the 14th sound and music computing conference</em> (pp. 175–180). Aalto University. <a href="https://doi.org/10.5281/zenodo.1401907">https://doi.org/10.5281/zenodo.1401907</a>
</div>
<div id="ref-Martin:2017ab" class="csl-entry" role="doc-biblioentry">
Martin, C. P., &amp; Torresen, J. (2017b). MicroJam: An app for sharing tiny touch-screen performances. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, 495–496. <a href="https://doi.org/10.5281/zenodo.1176334">https://doi.org/10.5281/zenodo.1176334</a>
</div>
<div id="ref-Martin:2018ag" class="csl-entry" role="doc-biblioentry">
Martin, C. P., &amp; Torresen, J. (2018a). <span>RoboJam</span>: A musical mixture density network for collaborative touchscreen interaction. In A. Liapis, J. J. Romero Cardalda, &amp; A. Ekárt (Eds.), <em>Computational intelligence in music, sound, art and design: International conference, <span>EvoMUSART</span></em> (Vol. 10783, pp. 161–176). Springer International Publishing. <a href="https://doi.org/10.1007/978-3-319-77583-8_11">https://doi.org/10.1007/978-3-319-77583-8_11</a>
</div>
<div id="ref-Martin:2018ai" class="csl-entry" role="doc-biblioentry">
Martin, C. P., &amp; Torresen, J. (2018b, December). Predictive musical interaction with MDRNNs. <em>NeurIPS 2018 Workshop on Machine Learning for Creativity and Design</em>. <a href="https://doi.org/10.5281/zenodo.2558826">https://doi.org/10.5281/zenodo.2558826</a>
</div>
<div id="ref-Martin:2019ab" class="csl-entry" role="doc-biblioentry">
Martin, C. P., &amp; Torresen, J. (2020). Data driven analysis of tiny touchscreen performance with MicroJam. <em>Computer Music Journal</em>, <em>43</em>(4), 41–57. <a href="https://doi.org/10.1162/COMJ_a_00536">https://doi.org/10.1162/COMJ_a_00536</a>
</div>
<div id="ref-Evolution:2013kc" class="csl-entry" role="doc-biblioentry">
Martin, C., Finkelmeier, M., &amp; Remington, J. (2013). <em><span>Ensemble Evolution</span>: Sounds from the treetops [album]</em> [Music recording]. <a href="https://ensembleevolution.bandcamp.com/album/sounds-from-the-treetops">https://ensembleevolution.bandcamp.com/album/sounds-from-the-treetops</a>
</div>
<div id="ref-Martin:2010rw" class="csl-entry" role="doc-biblioentry">
Martin, C., Forster, B., &amp; Cormick, H. (2010a). Audience interactive performance in “<span class="nocase">The Last Man to Die</span>". In T. Opie (Ed.), <em>Proceedings of the <span>Australasian</span> computer music conference</em> (pp. 89–91). Australasian Computer Music Association. <a href="http://hdl.handle.net/1885/101945">http://hdl.handle.net/1885/101945</a>
</div>
<div id="ref-Martin:2010dk" class="csl-entry" role="doc-biblioentry">
Martin, C., Forster, B., &amp; Cormick, H. (2010b). Cross-artform performance using networked interfaces: <span>L</span>ast <span>M</span>an to <span>D</span>ie’s <span>V</span>ital <span>LMTD</span>. In K. Beilharz, B. Bongers, A. Johnston, &amp; S. Ferguson (Eds.), <em>Proceedings of the international conference on new interfaces for musical expression</em> (pp. 204–207). <a href="https://doi.org/10.5281/zenodo.1177843">https://doi.org/10.5281/zenodo.1177843</a>
</div>
<div id="ref-Martin:2015mz" class="csl-entry" role="doc-biblioentry">
Martin, C., &amp; Gardner, H. (2015, February). That syncing feeling: Networked strategies for enabling ensemble creativity in i<span>P</span>ad musicians. <em>Proceedings of <span>C</span>reate<span>W</span>orld</em>. <a href="http://hdl.handle.net/1885/95216">http://hdl.handle.net/1885/95216</a>
</div>
<div id="ref-Martin:2014aa" class="csl-entry" role="doc-biblioentry">
Martin, C., &amp; Gardner, H. (2014, April). Preserving musical performance on touch-screens. <em>Proceedings of the <span>CHI</span> 2014 Workshop on Curating the Digital: Spaces for Art and Interaction</em>. <a href="https://doi.org/10.5281/zenodo.1175599">https://doi.org/10.5281/zenodo.1175599</a>
</div>
<div id="ref-Martin:2016aa" class="csl-entry" role="doc-biblioentry">
Martin, C., &amp; Gardner, H. (2016a, May). Can machine learning apply to musical ensembles? <em>Proceedings of the <span>CHI</span> Human-Centered Machine Learning Workshop</em>. <a href="https://doi.org/10.5281/zenodo.56379">https://doi.org/10.5281/zenodo.56379</a>
</div>
<div id="ref-Martin:2016ab" class="csl-entry" role="doc-biblioentry">
Martin, C., &amp; Gardner, H. (2016b, May). Free-improvised rehearsal-as-research for musical <span>HCI</span>. <em>Proceedings of the <span>CHI</span> Musical <span>HCI</span> Workshop</em>. <a href="https://doi.org/10.5281/zenodo.56378">https://doi.org/10.5281/zenodo.56378</a>
</div>
<div id="ref-Martin:2016rm" class="csl-entry" role="doc-biblioentry">
Martin, C., &amp; Gardner, H. (2016c). A percussion-focussed approach to preserving touch-screen improvisation. In D. England, T. Schiphorst, &amp; N. Bryan-Kinns (Eds.), <em>Curating the digital: Spaces for art and interaction</em> (pp. 51–72). Springer International Publishing. <a href="https://doi.org/10.1007/978-3-319-28722-5_5">https://doi.org/10.1007/978-3-319-28722-5_5</a>
</div>
<div id="ref-Martin:2014cr" class="csl-entry" role="doc-biblioentry">
Martin, C., Gardner, H., &amp; Swift, B. (2014a). Exploring percussive gesture on i<span>P</span>ads with <span>E</span>nsemble <span>M</span>etatone. <em>Proceedings of the <span>SIGCHI</span> Conference on Human Factors in Computing Systems</em>, 1025–1028. <a href="https://doi.org/10.1145/2556288.2557226">https://doi.org/10.1145/2556288.2557226</a>
</div>
<div id="ref-Martin:2014xp" class="csl-entry" role="doc-biblioentry">
Martin, C., Gardner, H., &amp; Swift, B. (2014b). <span>M</span>eta<span>T</span>ravels and <span>M</span>eta<span>L</span>onsdale: <span class="nocase">iPad</span> apps for percussive improvisation. <em><span>CHI</span> ’14 Extended Abstracts on Human Factors in Computing Systems</em>, 547–550. <a href="https://doi.org/10.1145/2559206.2574805">https://doi.org/10.1145/2559206.2574805</a>
</div>
<div id="ref-Martin:2015jk" class="csl-entry" role="doc-biblioentry">
Martin, C., Gardner, H., &amp; Swift, B. (2015). Tracking ensemble performance on touch-screens with gesture classification and transition matrices. In E. Berdahl &amp; J. Allison (Eds.), <em>Proceedings of the international conference on new interfaces for musical expression</em> (pp. 359–364). Louisiana State University. <a href="https://doi.org/10.5281/zenodo.1179130">https://doi.org/10.5281/zenodo.1179130</a>
</div>
<div id="ref-Martin:2016rp" class="csl-entry" role="doc-biblioentry">
Martin, C., Gardner, H., &amp; Swift, B. (2016). <em>Video figure: Exploring percussive gesture on <span class="nocase">iPads</span> with <span>Ensemble Metatone</span></em>. Zenodo. <a href="https://doi.org/10.5281/zenodo.51815">https://doi.org/10.5281/zenodo.51815</a>
</div>
<div id="ref-Martin:2016vn" class="csl-entry" role="doc-biblioentry">
Martin, C., Gardner, H., Swift, B., &amp; Martin, M. (2016a). Intelligent agents and networked buttons improve free-improvised ensemble music-making on touch-screens. <em>Proceedings of the <span>SIGCHI</span> Conference on Human Factors in Computing Systems</em>, 2295–2306. <a href="https://doi.org/10.1145/2858036.2858269">https://doi.org/10.1145/2858036.2858269</a>
</div>
<div id="ref-Martin:2015cr" class="csl-entry" role="doc-biblioentry">
Martin, C., Gardner, H., Swift, B., &amp; Martin, M. (2015). Music of 18 performances: Evaluating apps and agents with free improvisation. In J. Drummond, D. Hewitt, S. Lerner, &amp; I. Stevenson (Eds.), <em>Proceedings of the 2015 conference of the <span>Australasian Computer Music Association</span></em> (pp. 85–94). Australasian Computer Music Association. <a href="http://hdl.handle.net/1885/95205">http://hdl.handle.net/1885/95205</a>
</div>
<div id="ref-Martin:2016fu" class="csl-entry" role="doc-biblioentry">
Martin, C., Gardner, H., Swift, B., &amp; Martin, M. (2016b). <em>Video figure: Intelligent agents and networked buttons improve free-improvised ensemble music- making on touch-screens</em>. Zenodo. <a href="https://doi.org/10.5281/zenodo.51801">https://doi.org/10.5281/zenodo.51801</a>
</div>
<div id="ref-Martin:2013wd" class="csl-entry" role="doc-biblioentry">
Martin, C., Hopgood, C., &amp; Griffiths, J. (2013). <em>Ensemble metatone: Research rehearsal 2013-04-20, set 2</em>. ANU Research Publications. <a href="http://hdl.handle.net/1885/101473">http://hdl.handle.net/1885/101473</a>
</div>
<div id="ref-Ensemble-Metatone:2014sf" class="csl-entry" role="doc-biblioentry">
Martin, C., Hopgood, C., Griffiths, J., &amp; Lam, Y. (2014c). <em><span>Ensemble Metatone</span> [album]</em> [Music recording]. <a href="https://charlesmartin.bandcamp.com/album/ensemble-metatone/">https://charlesmartin.bandcamp.com/album/ensemble-metatone/</a>
</div>
<div id="ref-Martin:2014ac" class="csl-entry" role="doc-biblioentry">
Martin, C., Hopgood, C., Griffiths, J., &amp; Lam, Y. (2014d, March). <span>Ensemble Metatone: Loner Series Concert</span>. <em>You Are Here Festival</em>. <a href="https://youtu.be/vNdSjO7H9vE">https://youtu.be/vNdSjO7H9vE</a>
</div>
<div id="ref-Martin:2013it" class="csl-entry" role="doc-biblioentry">
Martin, C., Hopgood, C., Griffiths, J., &amp; Lam, Y. (2013a). <em>Ensemble metatone: Research rehearsal 2013-04-27</em>. ANU Research Publications. <a href="http://hdl.handle.net/1885/101471">http://hdl.handle.net/1885/101471</a>
</div>
<div id="ref-Martin:2013cs" class="csl-entry" role="doc-biblioentry">
Martin, C., Hopgood, C., Griffiths, J., &amp; Lam, Y. (2013b). <em>Ensemble metatone: Research rehearsal 2013-05-04, set 1</em>. ANU Research Publications. <a href="http://hdl.handle.net/1885/101470">http://hdl.handle.net/1885/101470</a>
</div>
<div id="ref-Martin:2013hb" class="csl-entry" role="doc-biblioentry">
Martin, C., Hopgood, C., Griffiths, J., &amp; Lam, Y. (2013c). <em>Ensemble metatone: Research rehearsal 2013-05-04, set 2</em>. ANU Research Publications. <a href="http://hdl.handle.net/1885/101469">http://hdl.handle.net/1885/101469</a>
</div>
<div id="ref-Martin:2016kq" class="csl-entry" role="doc-biblioentry">
Martin, C., Hopgood, C., Griffiths, J., &amp; Lam, Y. (2016). <em><span>E</span>nsemble <span>M</span>etatone 2013 rehearsal study performance data</em>. Zenodo. <a href="https://doi.org/10.5281/zenodo.51595">https://doi.org/10.5281/zenodo.51595</a>
</div>
<div id="ref-Martin:2013ec" class="csl-entry" role="doc-biblioentry">
Martin, C., Hopgood, C., Griffiths, J., &amp; Lam, Y. (2013d). <em>Ensemble metatone: Research concert 2013-08-03</em>. ANU Research Publications. <a href="http://hdl.handle.net/1885/101467">http://hdl.handle.net/1885/101467</a>
</div>
<div id="ref-Martin:2013qr" class="csl-entry" role="doc-biblioentry">
Martin, C., Hopgood, C., Griffiths, J., &amp; Lam, Y. (2013e). <em>Ensemble metatone: Research rehearsal 2013-04-20, set 1</em>. ANU Research Publications. <a href="http://hdl.handle.net/1885/101466">http://hdl.handle.net/1885/101466</a>
</div>
<div id="ref-Martin:2013la" class="csl-entry" role="doc-biblioentry">
Martin, C., Hopgood, C., Griffiths, J., &amp; Lam, Y. (2013f). <em>Ensemble metatone: Research rehearsal 2013-08-03</em>. ANU Research Publications. <a href="http://hdl.handle.net/1885/101468">http://hdl.handle.net/1885/101468</a>
</div>
<div id="ref-Martin:2014ab" class="csl-entry" role="doc-biblioentry">
Martin, C., Hopgood, C., Griffiths, J., &amp; Lam, Y. (2014e, August). <span class="nocase">Colour Music Concert with Ensemble Metatone</span>. <em><span>Colour Music Concert Series</span></em>. <a href="https://youtu.be/ICeHWlNRsgU">https://youtu.be/ICeHWlNRsgU</a>
</div>
<div id="ref-Martin:2015ab" class="csl-entry" role="doc-biblioentry">
Martin, C., Hopgood, C., Griffiths, J., &amp; Lam, Y. (2015). <em><span>Colour Music [Album]</span></em>. <a href="https://charlesmartin.bandcamp.com/album/colour-music">https://charlesmartin.bandcamp.com/album/colour-music</a>
</div>
<div id="ref-Martin:2013oq" class="csl-entry" role="doc-biblioentry">
Martin, C., Hopgood, C., &amp; Lam, Y. (2013). <em>Ensemble metatone: Research rehearsal 2013-04-21</em>. ANU Research Publications. <a href="http://hdl.handle.net/1885/101472">http://hdl.handle.net/1885/101472</a>
</div>
<div id="ref-Martin:2017ap" class="csl-entry" role="doc-biblioentry">
Martin, C., &amp; Hunter, A. (2017). <em>Andromeda is coming [album]</em>. <a href="https://collectedresonances.bandcamp.com/album/andromeda-is-coming">https://collectedresonances.bandcamp.com/album/andromeda-is-coming</a>
</div>
<div id="ref-Martin:2011oz" class="csl-entry" role="doc-biblioentry">
Martin, C., &amp; Lai, C.-H. (2011). <span class="nocase">Strike on Stage</span>: A percussion and media performance. In A. R. Jensenius, A. Tveit, R. I. Godoy, &amp; D. Overholt (Eds.), <em>Proceedings of the international conference on new interfaces for musical expression</em> (pp. 142–143). <a href="https://doi.org/10.5281/zenodo.1178103">https://doi.org/10.5281/zenodo.1178103</a>
</div>
<div id="ref-Martin:2016fc" class="csl-entry" role="doc-biblioentry">
Martin, C., Swift, B., &amp; Gardner, H. (2016). <em>Metatone-analysis v0.1</em>. <a href="https://doi.org/10.5281/zenodo.51710">https://doi.org/10.5281/zenodo.51710</a>
</div>
<div id="ref-McArthur:2021vj" class="csl-entry" role="doc-biblioentry">
McArthur, R. N., &amp; Martin, C. P. (2021). An application for evolutionary music composition using autoencoders. <em>Artificial Intelligence in Music, Sound, Art and Design: 10th International Conference, EvoMUSART 2021</em>, 443–458. https://doi.org/<a href="https://doi.org/10.1007/978-3-030-72914-1_29">https://doi.org/10.1007/978-3-030-72914-1_29</a>
</div>
<div id="ref-Naess:2019aa" class="csl-entry" role="doc-biblioentry">
Næss, T. R., &amp; Martin, C. P. (2019). A physical intelligent instrument using recurrent neural networks. In M. Queiroz &amp; A. X. Sedó (Eds.), <em>Proceedings of the international conference on new interfaces for musical expression</em> (pp. 79–82). UFRGS. <a href="http://www.nime.org/proceedings/2019/nime2019_016.pdf">http://www.nime.org/proceedings/2019/nime2019_016.pdf</a>
</div>
<div id="ref-Nygaard:2021wy" class="csl-entry" role="doc-biblioentry">
Nygaard, T. F., Martin, C. P., Howard, D., Torresen, J., &amp; Glette, K. (2021). Environmental adaptation of robot morphology and control through real-world evolution. <em>Evolutionary Computation</em>. <a href="https://doi.org/10.1162/evco_a_00291">https://doi.org/10.1162/evco_a_00291</a>
</div>
<div id="ref-Nygaard:2018aa" class="csl-entry" role="doc-biblioentry">
Nygaard, T. F., Martin, C. P., Samuelsen, E., Torresen, J., &amp; Glette, K. (2018). Real-world evolution adapts robot morphology and control to hardware limitations. <em>Proceedings of the Genetic and Evolutionary Computation Conference</em>, 125–132. <a href="https://doi.org/10.1145/3205455.3205567">https://doi.org/10.1145/3205455.3205567</a>
</div>
<div id="ref-Nygaard:2019aa" class="csl-entry" role="doc-biblioentry">
Nygaard, T. F., Martin, C. P., Torresen, J., &amp; Glette, K. (2019a). Evolving robots on easy mode: Towards a variable complexity controller for quadrupeds. In P. Kaufmann &amp; P. A. Castillo (Eds.), <em>International conference on the applications of evolutionary computation</em> (pp. 616–632). Springer International Publishing. <a href="https://doi.org/10.1007/978-3-030-16692-2_41">https://doi.org/10.1007/978-3-030-16692-2_41</a>
</div>
<div id="ref-Nygaard:2018ab" class="csl-entry" role="doc-biblioentry">
Nygaard, T. F., Martin, C. P., Torresen, J., &amp; Glette, K. (2019b). Self-modifying morphology experiments with <span>DyRET</span>: Dynamic robot for embodied testing. <em>Proc. Of the IEEE Int. Conf. On Robotics &amp; Automation (ICRA)</em>, 9446–9452. <a href="https://doi.org/10.1109/ICRA.2019.8793663">https://doi.org/10.1109/ICRA.2019.8793663</a>
</div>
<div id="ref-Nygaard:2021uj" class="csl-entry" role="doc-biblioentry">
Nygaard, T. F., Martin, C. P., Torresen, J., Glette, K., &amp; Howard, D. (2021). Real-world embodied <span>AI</span> through a morphologically adaptive quadruped robot through a morphologically adaptive quadruped robot. <em>Nature Machine Intelligence</em>. <a href="https://doi.org/10.1038/s42256-021-00320-3">https://doi.org/10.1038/s42256-021-00320-3</a>
</div>
<div id="ref-Nygaard:2018ac" class="csl-entry" role="doc-biblioentry">
Nygaard, T. F., Martin, C. P., Tørresen, J., &amp; Glette, K. (2018, April). Exploring mechanically self-reconfiguring robots for autonomous design. <em><span>ICRA</span> Workshop on Autonomous Robot Design</em>. <a href="http://arxiv.org/abs/1805.02965">http://arxiv.org/abs/1805.02965</a>
</div>
<div id="ref-Nygaard:2019ab" class="csl-entry" role="doc-biblioentry">
Nygaard, T. F., Nordmoen, J., Ellefsen, K. O., Martin, C. P., Tørresen, J., &amp; Glette, K. (2019). Experiences from real-world evolution with DyRET: Dynamic robot for embodied testing. In K. Bach &amp; M. Ruocco (Eds.), <em>Nordic artificial intelligence research and development</em> (Vol. 1056, pp. 58–68). Springer International Publishing. <a href="https://doi.org/10.1007/978-3-030-35664-4_6">https://doi.org/10.1007/978-3-030-35664-4_6</a>
</div>
<div id="ref-Nygaard:2019ac" class="csl-entry" role="doc-biblioentry">
Nygaard, T. F., Nordmoen, J., Martin, C. P., &amp; Glette, K. (2019, May). Lessons learned from real-world experiments with DyRET: The dynamic robot for embodied testing. <em><span>ICRA</span> Legged Locomotion Workshop</em>. <a href="http://arxiv.org/abs/1905.05626">http://arxiv.org/abs/1905.05626</a>
</div>
<div id="ref-NIME20_9" class="csl-entry" role="doc-biblioentry">
Proctor, R., &amp; Martin, C. P. (2020). A laptop ensemble performance system using recurrent neural networks. In R. Michon &amp; F. Schroeder (Eds.), <em>Proceedings of the international conference on new interfaces for musical expression</em> (pp. 43–48). Birmingham City University. <a href="https://www.nime.org/proceedings/2020/nime2020_paper9.pdf">https://www.nime.org/proceedings/2020/nime2020_paper9.pdf</a>
</div>
<div id="ref-Swift:2019aa" class="csl-entry" role="doc-biblioentry">
Swift, B., Martin, C. P., &amp; Hunter, A. (2019). Two perspectives on rebooting computer music and music education: Composition and computer science. <em>Proceedings of the <span>Australasian</span> Computer Music Conference</em>, 53–57. <a href="https://doi.org/10.25911/5e37e8d92ff89">https://doi.org/10.25911/5e37e8d92ff89</a>
</div>
<div id="ref-Wallace:2019aa" class="csl-entry" role="doc-biblioentry">
Wallace, B., &amp; Martin, C. P. (2019). Comparing models for harmony prediction in an interactive audio looper. In A. Ekárt, A. Liapis, &amp; M. L. Castro Pena (Eds.), <em>International conference on computational intelligence in music, sound, art and design</em> (pp. 173–187). Springer International Publishing. <a href="https://doi.org/10.1007/978-3-030-16667-0_12">https://doi.org/10.1007/978-3-030-16667-0_12</a>
</div>
<div id="ref-Wallace:2019ab" class="csl-entry" role="doc-biblioentry">
Wallace, B., Martin, C. P., &amp; Nymoen, K. (2019, October). Tracing from sound to movement with mixture density recurrent neural networks. <em>Proceedings of the 6th International Conference on Movement and Computing</em>. <a href="https://doi.org/10.1145/3347122.3371376">https://doi.org/10.1145/3347122.3371376</a>
</div>
<div id="ref-Wallace:2020aa" class="csl-entry" role="doc-biblioentry">
Wallace, B., Martin, C. P., Torresen, J., &amp; Nymoen, K. (2020). Towards movement generation with audio features. In <em>Proceedings of the 11th international conference on computational creativity</em> (pp. 284–287). Association for Computational Creativity. <a href="https://arxiv.org/abs/2011.13453">https://arxiv.org/abs/2011.13453</a>
</div>
<div id="ref-Wallace:2021vh" class="csl-entry" role="doc-biblioentry">
Wallace, B., Martin, C. P., Tørresen, J., &amp; Nymoen, K. (2021). Exploring the effect of sampling strategy on movement generation with generative neural networks. <em>Artificial Intelligence in Music, Sound, Art and Design: 10th International Conference, EvoMUSART 2021</em>, 344–359. https://doi.org/<a href="https://doi.org/10.1007/978-3-030-72914-1_23">https://doi.org/10.1007/978-3-030-72914-1_23</a>
</div>
<div id="ref-Weber:2019aa" class="csl-entry" role="doc-biblioentry">
Weber, A., Martin, C. P., Torresen, J., &amp; da Silva, B. C. (2019). Identifying reusable early-life options. <em>2019 Joint IEEE 9th International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob)</em>, 335–340. <a href="https://doi.org/10.1109/DEVLRN.2019.8850725">https://doi.org/10.1109/DEVLRN.2019.8850725</a>
</div>
</div>
</body>
</html>
